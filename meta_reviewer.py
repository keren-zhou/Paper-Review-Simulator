import openai
import os
import json
import pandas as pd
from pathlib import Path
from typing import Dict, Any, List
import argparse

# ==============================================================================
# --- 1. å…¨å±€é…ç½®ä¸å®¢æˆ·ç«¯åˆå§‹åŒ– ---
# ==============================================================================

def initialize_qwen_client() -> openai.OpenAI | None:
    """
    æ ¹æ®ç¯å¢ƒå˜é‡åˆå§‹åŒ–å¹¶è¿”å›åƒé—®å®¢æˆ·ç«¯ã€‚
    """
    api_key = os.getenv("DASHSCOPE_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯ï¼šç¯å¢ƒå˜é‡ DASHSCOPE_API_KEY æœªè®¾ç½®ï¼")
        return None
    
    try:
        client = openai.OpenAI(
            api_key=api_key,
            base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
        )
        print("âœ… åƒé—®å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸã€‚")
        return client
    except Exception as e:
        print(f"âŒ åˆå§‹åŒ–åƒé—®å®¢æˆ·ç«¯æ—¶å‡ºé”™: {e}")
        return None

# å°†å®¢æˆ·ç«¯åˆå§‹åŒ–æ¨è¿Ÿåˆ°å‡½æ•°ä¸­ï¼Œä½¿å…¶æˆä¸ºå…¨å±€å˜é‡
qwen_client = initialize_qwen_client()

# ==============================================================================
# --- 2. æ•°æ®åŠ è½½å‡½æ•° ---
# ==============================================================================

def load_json_data(file_path: Path) -> Dict[str, Any] | None:
    """åŠ è½½ JSON æ–‡ä»¶ (é€šå¸¸æ¥è‡ªæ­¥éª¤2çš„è®ºæ–‡æ ¸å¿ƒåˆ†æ)ã€‚"""
    print(f"   -> æ­£åœ¨åŠ è½½è®ºæ–‡æ ¸å¿ƒåˆ†ææ–‡ä»¶: {file_path.name}")
    if not file_path.exists():
        print(f"   âŒ é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ {file_path}")
        return None
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"   âŒ é”™è¯¯ï¼šåŠ è½½æˆ–è§£æ JSON æ–‡ä»¶å¤±è´¥: {e}")
        return None

def load_markdown_report(file_path: Path) -> str | None:
    """åŠ è½½ Markdown æ ¼å¼çš„å•ä¸ªå®¡ç¨¿äººæŠ¥å‘Šã€‚"""
    print(f"   -> æ­£åœ¨åŠ è½½å®¡ç¨¿äººæŠ¥å‘Š: {file_path.name}")
    if not file_path.exists():
        print(f"   âŒ é”™è¯¯ï¼šæ–‡ä»¶ä¸å­˜åœ¨ {file_path}")
        return None
    try:
        return file_path.read_text(encoding='utf-8')
    except Exception as e:
        print(f"   âŒ é”™è¯¯ï¼šè¯»å– Markdown æ–‡ä»¶å¤±è´¥: {e}")
        return None

def load_and_sample_csv_reviews(file_path: Path, n_samples: int = 2) -> str | None:
    """åŠ è½½ step5 è¾“å‡ºçš„ CSV æ–‡ä»¶ï¼Œå¹¶é‡‡æ ·æ­£é¢å’Œè´Ÿé¢å®¡ç¨¿æ„è§ä½œä¸ºå‚è€ƒã€‚"""
    print(f"   -> æ­£åœ¨åŠ è½½å¹¶é‡‡æ ·å‚è€ƒå®¡ç¨¿æ„è§: {file_path.name}")
    if not file_path.exists():
        print(f"   âŒ é”™è¯¯ï¼šå‚è€ƒå®¡ç¨¿æ„è§æ–‡ä»¶ä¸å­˜åœ¨ {file_path}")
        return "Reference review file not found."
    try:
        df = pd.read_csv(file_path)
        required_cols = ['review_rating', 'review_strengths', 'review_weaknesses', 'title']
        if not all(col in df.columns for col in required_cols):
            print(f"   âŒ é”™è¯¯ï¼šCSV æ–‡ä»¶ç¼ºå°‘å¿…éœ€çš„åˆ—ã€‚éœ€è¦: {required_cols}")
            return "Reference CSV is missing required columns."
        
        # å°†è¯„åˆ†è½¬æ¢ä¸ºå¯æ’åºçš„æ•°å€¼
        df['review_rating_num'] = pd.to_numeric(df['review_rating'].astype(str).str.extract(r'(\d+)')[0], errors='coerce')
        df.dropna(subset=['review_rating_num'], inplace=True)
        df['review_rating_num'] = df['review_rating_num'].astype(int)
        
        df_sorted = df.sort_values(by='review_rating_num', ascending=False)
        
        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ ·æœ¬
        if len(df_sorted) < n_samples * 2:
            n_samples = max(1, len(df_sorted) // 2) # å¦‚æœæ ·æœ¬ä¸è¶³ï¼Œåˆ™å–ä¸€åŠ
            if n_samples == 0:
                 print("   âš ï¸ è­¦å‘Šï¼šCSVä¸­çš„æœ‰æ•ˆè¯„è®ºå¤ªå°‘ï¼Œæ— æ³•é‡‡æ ·ã€‚")
                 return "Not enough valid reviews in the reference file to sample from."

        high_rated = df_sorted.head(n_samples)
        low_rated = df_sorted.tail(n_samples)

        reference_text = "--- é«˜åˆ†è¯„ä»·ç¤ºä¾‹ (å­¦ä¹ å…¶é£æ ¼å’Œçœ‹é‡çš„ä¼˜ç‚¹) ---\n\n"
        for _, row in high_rated.iterrows():
            reference_text += f"**è®ºæ–‡æ ‡é¢˜:** {row['title']}\n**è¯„åˆ†:** {row['review_rating']}\n**ä¼˜ç‚¹:**\n{row.get('review_strengths', 'N/A')}\n**ç¼ºç‚¹:**\n{row.get('review_weaknesses', 'N/A')}\n\n---\n"
        
        reference_text += "\n--- ä½åˆ†è¯„ä»·ç¤ºä¾‹ (å­¦ä¹ å…¶æ‰¹è¯„è§’åº¦å’Œå¸¸è§çš„æ‹’ç¨¿åŸå› ) ---\n\n"
        for _, row in low_rated.iterrows():
            reference_text += f"**è®ºæ–‡æ ‡é¢˜:** {row['title']}\n**è¯„åˆ†:** {row['review_rating']}\n**ä¼˜ç‚¹:**\n{row.get('review_strengths', 'N/A')}\n**ç¼ºç‚¹:**\n{row.get('review_weaknesses', 'N/A')}\n\n---\n"
        
        return reference_text
    except Exception as e:
        print(f"   âŒ é”™è¯¯ï¼šå¤„ç† CSV å‚è€ƒæ–‡ä»¶å¤±è´¥: {e}")
        return "Error processing reference review file."

# ==============================================================================
# --- 3. æ ¸å¿ƒåŠŸèƒ½ï¼šä¸»å¸­ AI (Meta-Reviewer) ---
# ==============================================================================

def get_conference_standards(tier: str, name: str) -> str:
    """æ ¹æ®ä¼šè®®ç­‰çº§å’Œå…·ä½“åç§°è¿”å›æ›´å…·é’ˆå¯¹æ€§çš„è¯„å®¡æ ‡å‡†æè¿°ã€‚"""
    # å¦‚æœç”¨æˆ·ç›´æ¥è¾“å…¥äº†CCFç­‰çº§ï¼Œåˆ™ä¼šè®®åå’Œç­‰çº§ç›¸åŒï¼Œé¿å…å†—ä½™æ˜¾ç¤º
    conf_display_name = f"{name} ({tier})" if name.upper() != tier.upper() else tier
    
    standards = {
        'CCF-A': f"This is a top-tier {conf_display_name} conference (e.g., NeurIPS, CVPR). Submissions are expected to be groundbreaking, with significant novelty, high impact, and technically flawless execution. Experimental validation must be comprehensive and rigorous.",
        'CCF-B': f"This is a reputable {conf_display_name} conference. Submissions should present solid, novel contributions to the field. Strong, complete experimental validation is crucial. The work should be a clear advancement over existing literature, but does not need to be revolutionary.",
        'CCF-C': f"This is a CCF-C conference ({name}). Submissions are expected to be correct, clear, and useful. Incremental contributions are acceptable if they are well-executed and properly evaluated. The focus is on technical correctness and clarity."
    }
    return standards.get(tier, standards['CCF-B'])

# --- [æ ¸å¿ƒä¿®æ”¹ 2] --- æ›´æ–°å‡½æ•°ä»¥æ¥æ”¶å’Œä½¿ç”¨ conference_name
def generate_final_review_with_qwen(
    paper_analysis: Dict[str, Any],
    quality_review: str,
    novelty_review: str,
    reference_reviews: str,
    conference_tier: str,
    conference_name: str
) -> str | None:
    """è°ƒç”¨å¤§æ¨¡å‹æ‰®æ¼”ä¸»å¸­AIè§’è‰²ï¼Œæ ¹æ®æŒ‡å®šçš„ä¼šè®®æ ‡å‡†ï¼Œç”Ÿæˆæœ€ç»ˆå®¡ç¨¿æ„è§ã€‚"""
    
    conference_standard_description = get_conference_standards(conference_tier, conference_name)
    conf_display_name = f"{conference_name} ({conference_tier})" if conference_name.upper() != conference_tier.upper() else conference_tier

    # --- [æ ¸å¿ƒç¾åŒ–ä¿®æ”¹] ä½¿ç”¨æ›´ä¸°å¯Œçš„ Markdown æ ¼å¼ ---
    prompt = f"""
You are a highly experienced Area Chair for a {conference_tier} AI conference. Your judgment standard is:
> {conference_standard_description}

**Task**: Synthesize the provided analysis and reviews into a final meta-review. Your goal is to be decisive, insightful, and constructive.

---
### **Input 1: Paper's Core Analysis**
```json
{json.dumps(paper_analysis, indent=2)}
```
***Input 2: Reviewer R1 - Technical Quality Report
{quality_review}
Input 3: Reviewer R2 - Novelty Assessment Report
{novelty_review}
Input 4: Reference Reviews from Similar Venues
{reference_reviews}
YOUR META-REVIEW & OUTPUT FORMAT
Generate a comprehensive Meta-Review. You MUST strictly follow the Markdown format below. Use headings, bold text, and lists to structure your report for clarity.
Meta-Review: Final Decision & Rebuttal Strategy
1. Final Verdict
Overall Recommendation
[Choose ONE: Strong Accept, Weak Accept, Borderline, Reject]
Justification: A concise, high-level justification for your decision, directly linking to the {conference_tier} standards. Explain the most critical factor that led to this verdict.
Executive Summary
A 2-3 sentence summary of the paper's core contribution and the key factors (both positive and negative) that influenced the final decision.
2. Detailed Analysis
Strengths
Primary Strength: (Synthesize and elaborate on the most significant strength).
Secondary Strength: (List other notable positive aspects).
Weaknesses
(Ranked by severity. Be critical and specific.)
[Critical] Weakness 1: (Describe the most severe flaw, e.g., a fundamental issue with the core claim, methodology, or experimental validation).
[Major] Weakness 2: (Describe a major issue, e.g., missing key comparisons to state-of-the-art, insufficient ablation studies).
[Minor] Weakness 3: (Describe a minor issue, e.g., presentation issues, unclear sections).
3. Guidance for Author Rebuttal
Predicted Reviewer Questions
Based on the identified weaknesses, anticipate the most challenging questions the authors will face.
Regarding Weakness #1: A reviewer will likely ask: "[Your pointed question here]"
Regarding Weakness #2: It is crucial to address: "[Another challenging question]"
Strategic Advice
Provide tactical advice for the authors. For instance: "To address the concerns about baseline comparisons, the authors should not just state that code is unavailable. Instead, they should create a detailed table comparing their reported metrics against the metrics reported in the original papers of the SOTA methods, and discuss the potential reasons for any discrepancies. This would demonstrate a higher level of academic rigor."
"""
    print("\n[ä¸»å¸­AI] æ­£åœ¨è°ƒç”¨åƒé—®å¤§æ¨¡å‹è¿›è¡Œæœ€ç»ˆåˆ†æä¸å†³ç­–...")
    try:
        response = qwen_client.chat.completions.create(
        model="qwen-plus",
        messages=[{"role": "user", "content": prompt}],
        max_tokens=4096,
        temperature=0.2, # ä½¿ç”¨è¾ƒä½çš„æ¸©åº¦ä»¥ä¿è¯å†³ç­–çš„ç¨³å®šæ€§
        )
        print("[ä¸»å¸­AI] âœ… æˆåŠŸæ”¶åˆ°åƒé—®çš„ Meta-Review æŠ¥å‘Šã€‚")
        return response.choices[0].message.content.strip()
    except Exception as e:
        print(f"[ä¸»å¸­AI] âŒ è°ƒç”¨åƒé—® API å¤±è´¥: {e}")
        return None
def run_meta_review(
    base_path_str: str,
    paper_name: str,
    conference_tier: str,
    conference_name: str, # <-- [æ–°å¢] æ¥æ”¶ name
    output_md_path: str
    ):
    """åè°ƒæ•´ä¸ª Meta-Review æµç¨‹çš„ä¸»å‡½æ•°ã€‚"""
    print(f"\n--- å¼€å§‹ä¸ºè®ºæ–‡ '{paper_name}' ç”Ÿæˆ Meta-Review ---")
    base_dir = Path(base_path_str)
    output_path = Path(output_md_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    # æ ¹æ®ä¼ å…¥çš„å‚æ•°æ„å»ºæ‰€æœ‰å¿…éœ€æ–‡ä»¶çš„å®Œæ•´è·¯å¾„
    analysis_json_path = base_dir / f"{paper_name}_comprehensive_analysis.json"
    quality_review_path = base_dir / f"{paper_name}_review_QualityInspector.md" # å®¡ç¨¿äºº1çš„æ–‡ä»¶å
    novelty_review_path = base_dir / f"{paper_name}_review_NoveltyAssessor.md"   # å®¡ç¨¿äºº2çš„æ–‡ä»¶å
    reference_csv_path = base_dir / "final_relevant_papers.csv"
    
    print("\n[æ­¥éª¤ 1/3] æ­£åœ¨åŠ è½½æ‰€æœ‰è¾“å…¥æ•°æ®...")
    paper_analysis = load_json_data(analysis_json_path)
    quality_review = load_markdown_report(quality_review_path)
    novelty_review = load_markdown_report(novelty_review_path)
    reference_reviews = load_and_sample_csv_reviews(reference_csv_path)
    
    # æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶æ˜¯å¦éƒ½å·²æˆåŠŸåŠ è½½
    if not all([paper_analysis, quality_review, novelty_review, reference_reviews]):
        print("\nâŒ å…³é”®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­ç”Ÿæˆ Meta-Reviewã€‚è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„å’Œå†…å®¹ã€‚")
        return
        
    print("\n[æ­¥éª¤ 2/3] æ‰€æœ‰æ•°æ®åŠ è½½æˆåŠŸï¼Œå‡†å¤‡æäº¤ç»™ä¸»å¸­ AI...")
    final_report = generate_final_review_with_qwen(
        paper_analysis,
        quality_review,
        novelty_review,
        reference_reviews,
        conference_tier,
        conference_name
    )
    
    if final_report:
        print("\n[æ­¥éª¤ 3/3] æ­£åœ¨ä¿å­˜æœ€ç»ˆçš„ Meta-Review æŠ¥å‘Š...")
        try:
            output_path.write_text(final_report, encoding='utf-8')
            print("\nğŸ‰ Meta Reviewer å…¨éƒ¨æµç¨‹æˆåŠŸï¼")
            print(f"æœ€ç»ˆçš„ Meta-Review æŠ¥å‘Šå·²ä¿å­˜åˆ°: {output_path.resolve()}")
        except Exception as e:
            print(f"âŒ ä¿å­˜æœ€ç»ˆæŠ¥å‘Šæ—¶å‡ºé”™: {e}")
    else:
        print("\nâŒ æœªèƒ½ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Šï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
if __name__ == "__main__":
    # è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(description="Meta Reviewer: ç»¼åˆæ‰€æœ‰è¯„å®¡ä¿¡æ¯å¹¶ç»™å‡ºæœ€ç»ˆå†³ç­–ã€‚")
    parser.add_argument("--base_path", type=str, required=True, help="åŒ…å«æ‰€æœ‰è®ºæ–‡ç›¸å…³è¾“å…¥æ–‡ä»¶çš„åŸºç¡€ç›®å½•ã€‚")
    parser.add_argument("--paper_name", type=str, required=True, help="è®ºæ–‡çš„æ–‡ä»¶å (ä¸å«æ‰©å±•å)ã€‚")
    parser.add_argument("--conference_tier", type=str, required=True, help="ç›®æ ‡ä¼šè®®ç­‰çº§ (ä¾‹å¦‚: CCF-A, CCF-B, CCF-C)ã€‚")
    # --- [æ–°å¢] ---
    parser.add_argument("--conference_name", type=str, required=True, help="ç›®æ ‡ä¼šè®®çš„å…·ä½“åç§° (ä¾‹å¦‚: CVPR)ã€‚")
    parser.add_argument("--output_path", type=str, required=True, help="ä¿å­˜æœ€ç»ˆ meta-review æŠ¥å‘Šçš„å®Œæ•´è·¯å¾„ã€‚")
    parser.add_argument("--config", type=str, help="Path to the configuration file (accepted but not used).")
    args = parser.parse_args()
    # æ£€æŸ¥å®¢æˆ·ç«¯æ˜¯å¦æˆåŠŸåˆå§‹åŒ–
    if qwen_client:
        run_meta_review(
            base_path_str=args.base_path,
            paper_name=args.paper_name,
            conference_tier=args.conference_tier,
            conference_name=args.conference_name, # <-- [æ–°å¢] ä¼ é€’äº† name
            output_md_path=args.output_path
        )
    else:
        print("ç¨‹åºå› åƒé—®å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥è€Œç»ˆæ­¢ã€‚")