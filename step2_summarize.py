# step2_analysis.py
# -*- coding: utf-8 -*-

import openai
import os
os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
import json
import time
from pathlib import Path
import re
import argparse # å¯¼å…¥ argparse ç”¨äºå¤„ç†å‘½ä»¤è¡Œå‚æ•°

# ==============================================================================
# --- 1. å…¨å±€é…ç½®ä¸å®¢æˆ·ç«¯åˆå§‹åŒ– ---
# ==============================================================================
# API Key å°†ç”±ä¸»æ§è„šæœ¬é€šè¿‡ç¯å¢ƒå˜é‡æ³¨å…¥
DASHSCOPE_API_KEY = os.getenv("DASHSCOPE_API_KEY")
if not DASHSCOPE_API_KEY:
    # è¿™æ˜¯ä¸€ä¸ªå®‰å…¨æ£€æŸ¥ï¼Œå¦‚æœè„šæœ¬è¢«ç‹¬ç«‹è¿è¡Œä¸”æœªè®¾ç½®ç¯å¢ƒå˜é‡ï¼Œåˆ™ä¼šæŠ¥é”™
    raise ValueError("é”™è¯¯ï¼šè¯·åœ¨æ‚¨çš„ç¯å¢ƒä¸­è®¾ç½® DASHSCOPE_API_KEY ç¯å¢ƒå˜é‡ï¼")

try:
    qwen_client = openai.OpenAI(
        api_key=DASHSCOPE_API_KEY,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )
    print("--- åƒé—® Qwen API å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ ---")
except Exception as e:
    print(f"åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯ï¼ˆç”¨äºåƒé—®ï¼‰æ—¶å‡ºé”™: {e}")
    exit()


# ==============================================================================
# --- 2. æ ¸å¿ƒåŠŸèƒ½å‡½æ•° (ä¸æ‚¨æä¾›çš„ç‰ˆæœ¬ä¿æŒä¸€è‡´) ---
# ==============================================================================

def extract_key_sections_improved(markdown_text: str) -> str:
    """ä» Markdown ä¸­æå–æ‘˜è¦ã€å¼•è¨€å’Œç»“è®ºã€‚"""
    print("--- æ­¥éª¤ 1/7: æå–è®ºæ–‡å…³é”®ç« èŠ‚ (æ‘˜è¦ã€å¼•è¨€ã€ç»“è®º) ---")
    INTRODUCTION_KEYWORDS = {'introduction'}
    CONCLUSION_KEYWORDS = {'conclusion', 'conclusions', 'summary', 'discussion', 'future work'}
    extracted_sections = {}
    
    abstract_pattern = re.compile(r"##?\s*Abstract\n(.*?)(?=\n##?\s)", re.IGNORECASE | re.DOTALL)
    abstract_match = abstract_pattern.search(markdown_text)
    if abstract_match:
        extracted_sections['abstract'] = abstract_match.group(0).strip()

    headings = list(re.finditer(r"^(##?)\s+(.*)", markdown_text, re.MULTILINE))
    sections = []
    for i, match in enumerate(headings):
        title_text = match.group(2).strip()
        start_pos = match.start()
        end_pos = headings[i+1].start() if i + 1 < len(headings) else len(markdown_text)
        content = markdown_text[start_pos:end_pos].strip()
        cleaned_title = re.sub(r"^\d+\.?\s*", "", title_text).lower()
        sections.append({"cleaned_title": cleaned_title, "content": content})

    for section in sections:
        if 'introduction' not in extracted_sections and section['cleaned_title'] in INTRODUCTION_KEYWORDS:
            extracted_sections['introduction'] = section['content']
        if 'conclusion' not in extracted_sections and section['cleaned_title'] in CONCLUSION_KEYWORDS:
            extracted_sections['conclusion'] = section['content']

    final_text_parts = [extracted_sections.get(key) for key in ['abstract', 'introduction', 'conclusion'] if extracted_sections.get(key)]
    if not final_text_parts:
        print("è­¦å‘Šï¼šæœªèƒ½æå–ä»»ä½•å…³é”®ç« èŠ‚ã€‚å°†ä½¿ç”¨å…¨æ–‡è¿›è¡Œåˆ†æã€‚")
        return markdown_text
    
    print("--- å…³é”®ç« èŠ‚æå–å®Œæˆ ---\n")
    return "\n\n---\n\n".join(final_text_parts)

def analyze_paper_summary_with_qwen(paper_content: str) -> dict | None:
    """è°ƒç”¨åƒé—®è¿›è¡Œè®ºæ–‡çš„â€œåŸºç¡€åˆ†æâ€ã€‚"""
    prompt = f"""
You are a world-class AI research assistant. Analyze the provided Abstract, Introduction, and Conclusion of a research paper and extract key information into a structured JSON format. Your output MUST be a single, valid JSON object with no other text. The JSON object must conform to the following structure: {{ "problem_statement": "...", "limitations_of_prior_work": ["..."], "key_innovations": [{{ "innovation_name": "...", "innovation_description": "..." }}], "supporting_evidence": {{ "theoretical_summary": "...", "experimental_summary": {{ "datasets": ["..."], "baselines": ["..."], "key_results": "..." }} }}, "keywords": ["..."] }}
---
{paper_content}
"""
    print("--- æ­¥éª¤ 2/7: æ­£åœ¨è°ƒç”¨åƒé—® API è¿›è¡Œè®ºæ–‡åŸºç¡€åˆ†æ... ---")
    start_time = time.time()
    try:
        response = qwen_client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": prompt}], max_tokens=4096, temperature=0.1)
        end_time = time.time()
        print("--- æˆåŠŸæ”¶åˆ° API å“åº”ï¼Œè€—æ—¶ {:.2f} ç§’ ---\n".format(end_time - start_time))
        response_content = response.choices[0].message.content
        cleaned_content = re.sub(r'```json\n(.*?)\n```', r'\1', response_content, flags=re.DOTALL)
        return json.loads(cleaned_content)
    except Exception as e:
        print("é”™è¯¯ï¼šè®ºæ–‡åŸºç¡€åˆ†æ API è°ƒç”¨æˆ– JSON è§£æå¤±è´¥: {}".format(e))
        return None

def extract_experimental_sections(markdown_text: str) -> str:
    """ä» Markdown ä¸­æå–æ–¹æ³•å’Œå®éªŒéƒ¨åˆ†ã€‚"""
    print("--- æ­¥éª¤ 3/7: æå–è®ºæ–‡å®éªŒç« èŠ‚ (æ–¹æ³•ã€å®éªŒ) ---")
    METHOD_KEYWORDS = {'method', 'methods', 'methodology', 'our method', 'proposed method', 'approach'}
    EXPERIMENT_KEYWORDS = {'experiment', 'experiments', 'experimental setup', 'implementation details', 'evaluation', 'results', 'comparisons', 'ablation study'}
    headings = list(re.finditer(r"^(##?)\s+(.*)", markdown_text, re.MULTILINE))
    sections = []
    for i, match in enumerate(headings):
        title_text = match.group(2).strip()
        start_pos = match.start()
        end_pos = headings[i+1].start() if i + 1 < len(headings) else len(markdown_text)
        content = markdown_text[start_pos:end_pos].strip()
        cleaned_title = re.sub(r"^\d+\.?\s*", "", title_text).lower()
        sections.append({"cleaned_title": cleaned_title, "content": content})

    extracted_content = [section['content'] for section in sections if section['cleaned_title'] in METHOD_KEYWORDS or section['cleaned_title'] in EXPERIMENT_KEYWORDS]
    if not extracted_content:
        print("è­¦å‘Šï¼šæœªèƒ½æ‰¾åˆ°æ–¹æ³•æˆ–å®éªŒç« èŠ‚ï¼Œå°†ä½¿ç”¨å…¨æ–‡è¿›è¡Œç»†èŠ‚åˆ†æã€‚")
        return markdown_text
    
    print("--- å®éªŒç« èŠ‚æå–å®Œæˆ ---\n")
    return "\n\n---\n\n".join(extracted_content)

def analyze_paper_details_with_qwen(paper_content: str) -> dict | None:
    """è°ƒç”¨åƒé—®è¿›è¡Œè®ºæ–‡çš„â€œç»†èŠ‚åˆ†æâ€ã€‚"""
    prompt = f"""
You are an expert AI assistant. Analyze the provided Methodology and Experimental sections of a research paper. Your goal is to extract two key pieces of information into a structured JSON format: 1. A single, de-duplicated list of all methods the paper compares itself against. 2. A list of the core technological components used to build the paper's own method. Your output MUST be a single, valid JSON object with no other text. The JSON object must follow this exact structure: {{ "comparison_methods": ["..."], "methodological_components": [{{ "component_name": "...", "component_usage": "..." }}] }}
---
{paper_content}
"""
    print("--- æ­¥éª¤ 4/7: æ­£åœ¨è°ƒç”¨åƒé—® API è¿›è¡Œè®ºæ–‡ç»†èŠ‚åˆ†æ... ---")
    start_time = time.time()
    try:
        response = qwen_client.chat.completions.create(model="qwen-plus", messages=[{"role": "user", "content": prompt}], max_tokens=4096, temperature=0.1)
        end_time = time.time()
        print("--- æˆåŠŸæ”¶åˆ° API å“åº”ï¼Œè€—æ—¶ {:.2f} ç§’ ---\n".format(end_time - start_time))
        response_content = response.choices[0].message.content
        cleaned_content = re.sub(r'```json\n(.*?)\n```', r'\1', response_content, flags=re.DOTALL)
        detail_result = json.loads(cleaned_content)
        # ç¡®ä¿å»é‡
        if 'comparison_methods' in detail_result and isinstance(detail_result['comparison_methods'], list):
            seen = set()
            unique_list = [item for item in detail_result['comparison_methods'] if item and item.lower() not in seen and not seen.add(item.lower())]
            detail_result['comparison_methods'] = sorted(unique_list, key=str.lower)
        return detail_result
    except Exception as e:
        print("é”™è¯¯ï¼šè®ºæ–‡ç»†èŠ‚åˆ†æ API è°ƒç”¨æˆ– JSON è§£æå¤±è´¥: {}".format(e))
        return None

def extract_references_from_markdown(markdown_text: str) -> list[str]:
    """ä½¿ç”¨ findall ç­–ç•¥æå–å®Œæ•´çš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨ã€‚"""
    print("--- æ­¥éª¤ 5/7: æå–å®Œæ•´çš„å‚è€ƒæ–‡çŒ®åˆ—è¡¨ ---")
    match = re.search(r'^##?\s+References\s*$', markdown_text, re.MULTILINE | re.IGNORECASE)
    if not match:
        print("è­¦å‘Šï¼šåœ¨ Markdown æ–‡ä»¶ä¸­æœªæ‰¾åˆ° 'References' ç« èŠ‚ã€‚")
        return []
    references_section = markdown_text[match.start():]
    references_section = re.sub(r'^##?\s+References\s*', '', references_section, count=1, flags=re.IGNORECASE).strip()
    pattern = re.compile(r'(\[\d+\].*?)(?=\s*\[\d+\]|$)', re.DOTALL)
    raw_refs = pattern.findall(references_section)
    extracted_refs = [re.sub(r'\s+', ' ', ref).strip() for ref in raw_refs if ref.strip()]
    if not extracted_refs:
        print("è­¦å‘Šï¼šæœªèƒ½æå–å‡ºä»»ä½•æ–‡çŒ®æ¡ç›®ã€‚")
    else:
        print("--- æˆåŠŸæå– {} æ¡å®Œæ•´çš„å‚è€ƒæ–‡çŒ® ---\n".format(len(extracted_refs)))
    return extracted_refs

def link_method_to_reference_by_citation(method_name: str, full_text: str, references_list: list[str]) -> tuple[str | None, str | None]:
    """é€šè¿‡å¼•ç”¨ç¼–å·å°†æ–¹æ³•é“¾æ¥åˆ°å‚è€ƒæ–‡çŒ®ã€‚"""
    pattern = re.compile(r'\b' + re.escape(method_name) + r'\b[^\]]*?\[(\d+)', re.IGNORECASE)
    match = pattern.search(full_text)
    if not match:
        return None, None
    citation_number = match.group(1)
    ref_pattern = re.compile(r'^\s*\[\s*' + citation_number + r'\s*\]')
    for ref in references_list:
        if ref_pattern.match(ref):
            return citation_number, ref
    return citation_number, None


# ==============================================================================
# --- 3. ç»Ÿä¸€çš„ä¸»æµç¨‹æ§åˆ¶å™¨ (å·²ä¿®æ”¹ä¸ºæ¥æ”¶å‚æ•°) ---
# ==============================================================================

def run_comprehensive_analysis(markdown_path: str, output_json_path: str):
    """
    ä»æŒ‡å®šçš„ Markdown æ–‡ä»¶ç”Ÿæˆç»¼åˆåˆ†æ JSONã€‚
    :param markdown_path: è¾“å…¥çš„ Markdown æ–‡ä»¶è·¯å¾„ã€‚
    :param output_json_path: è¾“å‡ºçš„ JSON æ–‡ä»¶è·¯å¾„ã€‚
    """
    md_file = Path(markdown_path)
    output_file = Path(output_json_path)

    if not md_file.exists():
        print(f"é”™è¯¯ï¼šè¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {markdown_path}")
        return

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_file.parent.mkdir(parents=True, exist_ok=True)

    print(f"--- æ­£åœ¨è¯»å– Markdown æ–‡ä»¶: {md_file.name} ---\n")
    full_text = md_file.read_text(encoding='utf-8')

    # --- Part 1: æ‰§è¡ŒåŸºç¡€åˆ†æ ---
    key_sections_text = extract_key_sections_improved(full_text)
    base_analysis_data = analyze_paper_summary_with_qwen(key_sections_text)
    if not base_analysis_data:
        print("âŒ è®ºæ–‡åŸºç¡€åˆ†æå¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
        return

    # --- Part 2: æ‰§è¡Œç»†èŠ‚åˆ†æ ---
    experimental_sections_text = extract_experimental_sections(full_text)
    detail_analysis_data = analyze_paper_details_with_qwen(experimental_sections_text)
    if not detail_analysis_data:
        print("âŒ è®ºæ–‡ç»†èŠ‚åˆ†æå¤±è´¥ï¼Œæµç¨‹ç»ˆæ­¢ã€‚")
        return

    # --- Part 3: é“¾æ¥å‚è€ƒæ–‡çŒ® ---
    references = extract_references_from_markdown(full_text)
    print("--- æ­¥éª¤ 6/7: å¼€å§‹é“¾æ¥å‚è€ƒæ–‡çŒ® ---")
    comparison_methods = detail_analysis_data.get("comparison_methods", [])
    linked_methods = []
    for method in comparison_methods:
        citation_num, found_ref = link_method_to_reference_by_citation(method, full_text, references)
        reference_text = "Citation not found in text"
        if citation_num and found_ref:
            reference_text = found_ref
            print(f"  - âœ… æˆåŠŸåŒ¹é… '{method}' -> å¼•ç”¨ [{citation_num}]")
        elif citation_num and not found_ref:
            reference_text = f"Found citation [{citation_num}] in text, but no matching entry in reference list."
            print(f"  - âš ï¸  '{method}' æ‰¾åˆ°å¼•ç”¨ [{citation_num}]ï¼Œä½†æœªåœ¨æ–‡çŒ®åˆ—è¡¨ä¸­åŒ¹é…ã€‚")
        else:
            print(f"  - âŒ æœªèƒ½ä¸º '{method}' åœ¨æ•´ä¸ªæ–‡æ¡£ä¸­æ‰¾åˆ°å¼•ç”¨ç¼–å·ã€‚")
        linked_methods.append({"method_name": method, "reference": reference_text})
    print("--- å‚è€ƒæ–‡çŒ®é“¾æ¥å®Œæˆ ---\n")

    # --- Part 4: åˆå¹¶æ‰€æœ‰åˆ†æç»“æœåˆ°ä¸€ä¸ª JSON å¯¹è±¡ ---
    print("--- æ­¥éª¤ 7/7: æ­£åœ¨åˆå¹¶æ‰€æœ‰åˆ†æç»“æœ... ---")
    
    comprehensive_json = {
        "paper_summary": base_analysis_data,
        "experimental_details": {
            "methodological_components": detail_analysis_data.get("methodological_components", []),
            "comparison_methods_with_references": linked_methods
        }
    }
    
    # --- Part 5: ä¿å­˜æœ€ç»ˆçš„ç»¼åˆæ–‡ä»¶ ---
    with open(str(output_file), 'w', encoding='utf-8') as f:
        json.dump(comprehensive_json, f, ensure_ascii=False, indent=4)
        
    print(f"\nğŸ‰ Step 2 æˆåŠŸï¼æœ€ç»ˆçš„ç»¼åˆåˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file.resolve()}")


# ==============================================================================
# --- 4. è„šæœ¬å…¥å£ (å·²ä¿®æ”¹ä¸ºæ¥æ”¶å‘½ä»¤è¡Œå‚æ•°) ---
# ==============================================================================
if __name__ == "__main__":
    # è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(description="Step 2: Create a comprehensive JSON analysis from a paper's Markdown file.")
    parser.add_argument("--markdown_path", type=str, required=True, help="Path to the input Markdown file generated by step1.")
    parser.add_argument("--output_path", type=str, required=True, help="Path to save the output comprehensive_analysis.json file.")
    parser.add_argument("--config", type=str, help="Path to the configuration file (accepted but not used in this script).")
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ (è™½ç„¶ä¸»å‡½æ•°é‡Œä¹Ÿæ£€æŸ¥äº†ï¼Œä½†åœ¨è¿™é‡Œæå‰æ£€æŸ¥å¯ä»¥æä¾›æ›´å¿«çš„åé¦ˆ)
    if not Path(args.markdown_path).exists():
         print("="*60)
         print(f"é”™è¯¯ï¼šè¾“å…¥çš„ Markdown æ–‡ä»¶ '{args.markdown_path}' ä¸å­˜åœ¨ã€‚")
         print("è¯·ç¡®ä¿ Step 1 å·²æˆåŠŸè¿è¡Œï¼Œå¹¶æä¾›äº†æ­£ç¡®çš„è·¯å¾„ã€‚")
         print("="*60)
    else:
        # ä½¿ç”¨ä»å‘½ä»¤è¡Œè·å–çš„è·¯å¾„è°ƒç”¨ä¸»æµç¨‹å‡½æ•°
        run_comprehensive_analysis(
            markdown_path=args.markdown_path,
            output_json_path=args.output_path
        )